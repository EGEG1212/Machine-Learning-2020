{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 랜덤 포레스트(Random Forest)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_name_df = pd.read_csv('../00.data/UCI_HAR_Dataset/features.txt', sep='\\s+', header=None, names=['col_index','col_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_feature_name_df(old_df):\n",
    "    dup_df = pd.DataFrame({'dup_cnt':feature_name_df.groupby('col_name').cumcount()})\n",
    "    new_df = pd.merge(old_df.reset_index(), dup_df.reset_index())\n",
    "    new_df['col_name'] = new_df[['col_name', 'dup_cnt']].\\\n",
    "        apply(lambda x: x[0]+'_'+str(x[1]) if x[1] > 0 else x[0], axis=1)\n",
    "    new_df = new_df.drop(['index'], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_df = get_new_feature_name_df(feature_name_df)\n",
    "feature_list = list(new_feature_df.col_name.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../00.data/UCI_HAR_Dataset/train/X_train.txt', \n",
    "                      header=None, sep='\\s+', names=feature_list)\n",
    "X_test = pd.read_csv('../00.data/UCI_HAR_Dataset/test/X_test.txt', \n",
    "                     header=None, sep='\\s+', names=feature_list)\n",
    "y_train = pd.read_csv('../00.data/UCI_HAR_Dataset/train/y_train.txt', \n",
    "                      header=None, sep='\\s+', names=['action'])\n",
    "y_test = pd.read_csv('../00.data/UCI_HAR_Dataset/test/y_test.txt', \n",
    "                     header=None, sep='\\s+', names=['action'])\n",
    "# ---------------------------------------------------------------데이터준비 끝   "
   ]
  },
  {
   "source": [
    "## 랜덤 포레스트 모델 생성/학습/예측/평가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "랜덤 포레스트 정확도: 0.9274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'랜덤 포레스트 정확도: {acc:.4f}')\n",
    "#03_ex파일에 디시전트리로 0.8717나왔는데.. 오늘 랜덤포레스트로 0.9220 올랐다!\n",
    "#여러모델로하면좋은거다???"
   ]
  },
  {
   "source": [
    "### 최적 파라미터 찾기 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "rf_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[ 10, 30, 50, 100, 200],\n",
    "     'max_depth': [8, 12, 16],\n",
    "     'min_samples_split': [12, 16, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "최고 평균 정확도: 0.9146\n최적 파라미터: {'max_depth': 8, 'min_samples_split': 12, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=156, n_jobs=-1)#cpu코어를최대한사용해서작업하라 더 빨리하라고!!그래도시간걸림;\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid=params, cv=3, n_jobs=-1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print(f'최고 평균 정확도: {grid_cv.best_score_:.4f}')\n",
    "print('최적 파라미터:', grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   param_n_estimators param_max_depth param_min_samples_split  mean_test_score\n",
       "0                  10               8                      12         0.897850\n",
       "1                  30               8                      12         0.908324\n",
       "2                  50               8                      12         0.914581\n",
       "3                 100               8                      12         0.911861\n",
       "4                 200               8                      12         0.911861\n",
       "5                  10               8                      16         0.897443\n",
       "6                  30               8                      16         0.903155\n",
       "7                  50               8                      16         0.907781\n",
       "8                 100               8                      16         0.909414\n",
       "9                 200               8                      16         0.908325\n",
       "10                 10               8                      20         0.898532\n",
       "11                 30               8                      20         0.906829\n",
       "12                 50               8                      20         0.911317\n",
       "13                100               8                      20         0.907510\n",
       "14                200               8                      20         0.904653\n",
       "15                 10              12                      12         0.891459\n",
       "16                 30              12                      12         0.899076\n",
       "17                 50              12                      12         0.904789\n",
       "18                100              12                      12         0.905197\n",
       "19                200              12                      12         0.907510\n",
       "20                 10              12                      16         0.900572\n",
       "21                 30              12                      16         0.906693\n",
       "22                 50              12                      16         0.909685\n",
       "23                100              12                      16         0.910093\n",
       "24                200              12                      16         0.904653\n",
       "25                 10              12                      20         0.896900\n",
       "26                 30              12                      20         0.900301\n",
       "27                 50              12                      20         0.906421\n",
       "28                100              12                      20         0.907509\n",
       "29                200              12                      20         0.905333\n",
       "30                 10              16                      12         0.892820\n",
       "31                 30              16                      12         0.902884\n",
       "32                 50              16                      12         0.906149\n",
       "33                100              16                      12         0.905606\n",
       "34                200              16                      12         0.906014\n",
       "35                 10              16                      16         0.893499\n",
       "36                 30              16                      16         0.900980\n",
       "37                 50              16                      16         0.905605\n",
       "38                100              16                      16         0.903564\n",
       "39                200              16                      16         0.905333\n",
       "40                 10              16                      20         0.891187\n",
       "41                 30              16                      20         0.902069\n",
       "42                 50              16                      20         0.905334\n",
       "43                100              16                      20         0.906830\n",
       "44                200              16                      20         0.908598"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_n_estimators</th>\n      <th>param_max_depth</th>\n      <th>param_min_samples_split</th>\n      <th>mean_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>8</td>\n      <td>12</td>\n      <td>0.897850</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>8</td>\n      <td>12</td>\n      <td>0.908324</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50</td>\n      <td>8</td>\n      <td>12</td>\n      <td>0.914581</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>8</td>\n      <td>12</td>\n      <td>0.911861</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200</td>\n      <td>8</td>\n      <td>12</td>\n      <td>0.911861</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10</td>\n      <td>8</td>\n      <td>16</td>\n      <td>0.897443</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>30</td>\n      <td>8</td>\n      <td>16</td>\n      <td>0.903155</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>50</td>\n      <td>8</td>\n      <td>16</td>\n      <td>0.907781</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>100</td>\n      <td>8</td>\n      <td>16</td>\n      <td>0.909414</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>200</td>\n      <td>8</td>\n      <td>16</td>\n      <td>0.908325</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>8</td>\n      <td>20</td>\n      <td>0.898532</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>30</td>\n      <td>8</td>\n      <td>20</td>\n      <td>0.906829</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>50</td>\n      <td>8</td>\n      <td>20</td>\n      <td>0.911317</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>100</td>\n      <td>8</td>\n      <td>20</td>\n      <td>0.907510</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>200</td>\n      <td>8</td>\n      <td>20</td>\n      <td>0.904653</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0.891459</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>30</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0.899076</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>50</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0.904789</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>100</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0.905197</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>200</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0.907510</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>10</td>\n      <td>12</td>\n      <td>16</td>\n      <td>0.900572</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>30</td>\n      <td>12</td>\n      <td>16</td>\n      <td>0.906693</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>50</td>\n      <td>12</td>\n      <td>16</td>\n      <td>0.909685</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>100</td>\n      <td>12</td>\n      <td>16</td>\n      <td>0.910093</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>200</td>\n      <td>12</td>\n      <td>16</td>\n      <td>0.904653</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>10</td>\n      <td>12</td>\n      <td>20</td>\n      <td>0.896900</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>30</td>\n      <td>12</td>\n      <td>20</td>\n      <td>0.900301</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>50</td>\n      <td>12</td>\n      <td>20</td>\n      <td>0.906421</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>100</td>\n      <td>12</td>\n      <td>20</td>\n      <td>0.907509</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>200</td>\n      <td>12</td>\n      <td>20</td>\n      <td>0.905333</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>10</td>\n      <td>16</td>\n      <td>12</td>\n      <td>0.892820</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>30</td>\n      <td>16</td>\n      <td>12</td>\n      <td>0.902884</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>50</td>\n      <td>16</td>\n      <td>12</td>\n      <td>0.906149</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>100</td>\n      <td>16</td>\n      <td>12</td>\n      <td>0.905606</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>200</td>\n      <td>16</td>\n      <td>12</td>\n      <td>0.906014</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>10</td>\n      <td>16</td>\n      <td>16</td>\n      <td>0.893499</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>30</td>\n      <td>16</td>\n      <td>16</td>\n      <td>0.900980</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>50</td>\n      <td>16</td>\n      <td>16</td>\n      <td>0.905605</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>100</td>\n      <td>16</td>\n      <td>16</td>\n      <td>0.903564</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>200</td>\n      <td>16</td>\n      <td>16</td>\n      <td>0.905333</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>10</td>\n      <td>16</td>\n      <td>20</td>\n      <td>0.891187</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>30</td>\n      <td>16</td>\n      <td>20</td>\n      <td>0.902069</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>50</td>\n      <td>16</td>\n      <td>20</td>\n      <td>0.905334</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>100</td>\n      <td>16</td>\n      <td>20</td>\n      <td>0.906830</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>200</td>\n      <td>16</td>\n      <td>20</td>\n      <td>0.908598</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df = pd.DataFrame(grid_cv.cv_results_)\n",
    "df = df[['param_n_estimators', 'param_max_depth', 'param_min_samples_split', 'mean_test_score']]\n",
    "df"
   ]
  },
  {
   "source": [
    "- 튜닝된 파라미터로 재평가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "최적 파라미터 랜덤 포레스트 정확도: 0.9141\n"
     ]
    }
   ],
   "source": [
    "best_clf = grid_cv.best_estimator_\n",
    "pred = best_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'최적 파라미터 랜덤 포레스트 정확도: {acc:.4f}')"
   ]
  },
  {
   "source": [
    "### 재탐색"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "최고 평균 정확도: 0.9085\n최적 파라미터: {'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [10, 50, 100]\n",
    "}\n",
    "rf_clf = RandomForestClassifier(random_state=156, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid=params, cv=3, n_jobs=-1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print(f'최고 평균 정확도: {grid_cv.best_score_:.4f}')\n",
    "print('최적 파라미터:', grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "최적 파라미터 랜덤 포레스트 정확도: 0.9247\n"
     ]
    }
   ],
   "source": [
    "best_clf = grid_cv.best_estimator_\n",
    "pred = best_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'최적 파라미터 랜덤 포레스트 정확도: {acc:.4f}')"
   ]
  },
  {
   "source": [
    "## K 최근접 이웃(K-Nearest Neighbor)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9015948422124194"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "#학습을 안하는데도 시간이 좀 걸림 ㅋㅋ\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, pred)\n",
    "#결과값 0.9015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}