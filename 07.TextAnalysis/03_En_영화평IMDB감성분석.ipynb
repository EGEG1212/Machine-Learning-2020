{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB 영화평 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../00.data/IMDB/labeledTrainData.tsv', header=0, sep='\\t', quoting=3)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         25000 non-null  object\n",
      " 1   sentiment  25000 non-null  int64 \n",
      " 2   review     25000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally sta'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review[0][:1000] #첫번째글. 1000번캐릭터까지확인\n",
    "#<br /><br /> 태그가 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <br />태그는 공백으로 변환\n",
    "df['review'] = df.review.str.replace('<br />', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 이외의 문자는 공백으로 변환(제거)\n",
    "import re\n",
    "\n",
    "df['review'] = df.review.apply(lambda x: re.sub('[^a-zA-Z]', ' ', x)) # X에 대해서 [^a-zA-Z]아닌놈^들은 공백으로 바꿔라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17500, 1), (7500, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_df = df.drop(['id', 'sentiment'], axis=1, inplace=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_df, df.sentiment, test_size=0.3, random_state=156 #feature_df데이터프레임을 줬더니, 아래서 컬럼지점해줘야하더라.. /y값 시리즈 df.sentiment 로 줌\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>This version moved a little slow for my taste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23599</th>\n",
       "      <td>I really enjoyed this film because I have a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11331</th>\n",
       "      <td>Saw this in the theater in     and fell out o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15745</th>\n",
       "      <td>Recently I was looking for the newly issued W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Escaping the life of being pimped by her fath...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "3724    This version moved a little slow for my taste...\n",
       "23599   I really enjoyed this film because I have a t...\n",
       "11331   Saw this in the theater in     and fell out o...\n",
       "15745   Recently I was looking for the newly issued W...\n",
       "845     Escaping the life of being pimped by her fath..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3724     0\n",
       "23599    1\n",
       "11331    1\n",
       "15745    1\n",
       "845      1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CountVectorizer의 경우,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "count_vect.fit(X_train.review) #df다보니 컬럼지정해줘야함 .review\n",
    "X_train_count = count_vect.transform(X_train.review) # 꼭 두단계를 거쳐야 train, test같은 인덱스를 가짐\n",
    "X_test_count = count_vect.transform(X_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.886"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=10)\n",
    "lr_clf.fit(X_train_count, y_train)\n",
    "pred = lr_clf.predict(X_test_count)\n",
    "accuracy_score(y_test, pred) #결과값 정확도0.886 88%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "tfidf_vect.fit(X_train.review)\n",
    "X_train_tfidf = tfidf_vect.transform(X_train.review) # 꼭 두단계를 거쳐야 train, test같은 인덱스를 가짐\n",
    "X_test_tfidf = tfidf_vect.transform(X_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8936"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=10)\n",
    "lr_clf.fit(X_train_tfidf, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf)\n",
    "accuracy_score(y_test, pred)#결과값 정확도0.8936 89% 조금올랐음;ㅋㅋ확실하게좋다는아닌데!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간들여 모은 tfidf_vect 자료\n",
    "### 모델 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/imdb_lr.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tfidf_vect, 'model/imdb_vect.pkl') #피클데이터라 뒤에 .pkl붙여주는게 관례\n",
    "joblib.dump(lr_clf, 'model/imdb_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#함부로지우는거아니다아ㅠㅠㅠㅠ\n",
    "#del tfidf_vect\n",
    "#del lr_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델에서 읽어오기\n",
    "new_vect = joblib.load('model/imdb_vect.pkl')\n",
    "new_lr = joblib.load('model/imdb_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#트레인은 할필요없다 #new_X_train = new_vect.transform(X_train.review) # 꼭 두단계를 거쳐야 train, test같은 인덱스를 가짐\n",
    "new_X_test = new_vect.transform(X_test.review)\n",
    "#시간이 쫌 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8936"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = new_lr.predict(new_X_test)\n",
    "accuracy_score(y_test, pred)\n",
    "#결과값0.8936 위에서한것과 모델불러온것과 값이 똑같! 시간절약을위해 이렇게하는것!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline을 써서 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression(C=10))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train.review, y_train)\n",
    "pred = pipeline.predict(X_test.review)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Count Vectorizer + Logistic Regression 정확도: {acc:.4f}')\n",
    "#시간 좀 걸림; 결과값 0.8860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8bc8cb9519c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model/pipeline.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'model/pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델저장이아닌데; 뭘 불러오는거지..\n",
    "new_pipe = joblib.load('model/pipline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer + Logistic Regression 정확도: 0.8860\n"
     ]
    }
   ],
   "source": [
    "pred = new_pipe.predict(X_test.review)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Count Vectorizer + Logistic Regression 정확도: {acc:.4f}')\n",
    "#저장한 모델도 위와같은 결과 정확도 0.8860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['analyzer', 'binary', 'decode_error', 'dtype', 'encoding', 'input', 'lowercase', 'max_df', 'max_features', 'min_df', 'ngram_range', 'norm', 'preprocessor', 'smooth_idf', 'stop_words', 'strip_accents', 'sublinear_tf', 'token_pattern', 'tokenizer', 'use_idf', 'vocabulary'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vect.get_params().keys()"
   ]
  },
  {
   "source": [
    "## 최적의 하이퍼파라미터도출"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfudfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "params = ({\n",
    "    'tfidf_vect__max_df': [100, 300, 500],\n",
    "    'lr_clf__C': [1, 5, 10]\n",
    "})\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)\n",
    "# 교수님결과 Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
    "#[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "#[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  4.7min finished\n",
    "#{'lr_clf__C': 5, 'tfidf_vect__max_df': 500} 0.8664572301433043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_pipe.predict(X_test.review)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Tfidf Vectorizer + Logistic Regression 정확도: {acc:.4f}') \n",
    "#교수님결과정확도: 0.8788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  6.0min finished\n",
      "{'new_lr__C': 5, 'new_vect__max_df': 500} 0.8664572301433043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('new_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('new_lr', LogisticRegression(C=10))\n",
    "])\n",
    "params = {\n",
    "    'new_vect__max_df': [100, 300, 500],\n",
    "    'new_lr__C': [1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)\n",
    "# 결과값: Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
    "# [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "# [Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  6.0min finished\n",
    "# {'new_lr__C': 5, 'new_vect__max_df': 500} 0.8664572301433043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer + Logistic Regression 정확도: 0.8788\n"
     ]
    }
   ],
   "source": [
    "pred = grid_pipe.predict(X_test.review)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Count Vectorizer + Logistic Regression 정확도: {acc:.4f}') #결과값: 정확도: 0.8788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  1.3min finished\n",
      "{'new_lr__C': 8, 'new_vect__max_df': 1000, 'new_vect__min_df': 2} 0.8732002767071286\n"
     ]
    }
   ],
   "source": [
    "#지우연씨 0.8949 능가해보고싶은데 못미침 ㅋ\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('new_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('new_lr', LogisticRegression(C=10))\n",
    "])\n",
    "params = {\n",
    "    'new_vect__max_df': [800, 1000],\n",
    "    'new_vect__min_df': [2],\n",
    "    'new_lr__C': [8, 20, 30]\n",
    "}\n",
    "\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_) #결과0.8732 되려떨어지면우짜냐 ㅋㅋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}